

<!DOCTYPE html>
<html class="writer-html5" lang="english" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Module 4 - Networks &mdash; MiniTorch 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="_static/thebelab.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Convolution" href="convolution.html" />
    <link rel="prev" title="GPU Programming" href="cuda.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MiniTorch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Workspace Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlprimer.html">ML Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="module0.html">Module 0 - Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="module1.html">Module 1 - Auto-Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="module2.html">Module 2 - Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="module3.html">Module 3 - Efficiency</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Module 4 - Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="convolution.html">Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="pooling.html">Pooling</a></li>
<li class="toctree-l2"><a class="reference internal" href="softmax.html">Softmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tasks">Tasks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#task-4-1-1d-convolution">Task 4.1: 1D Convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-2-2d-convolution">Task 4.2: 2D Convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-3-pooling">Task 4.3: Pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-4-softmax-and-dropout">Task 4.4: Softmax and Dropout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-4b-extra-credit">Task 4.4b: Extra Credit</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-4-5-training-an-image-classifier">Task 4.5: Training an Image Classifier</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MiniTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Module 4 - Networks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/module4.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-4-networks">
<h1>Module 4 - Networks<a class="headerlink" href="#module-4-networks" title="Permalink to this headline">¶</a></h1>
<a class="reference internal image-reference" href="_images/orig.png"><img alt="_images/orig.png" class="align-center" src="_images/orig.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist2.png"><img alt="_images/mnist2.png" class="align-center" src="_images/mnist2.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist5.png"><img alt="_images/mnist5.png" class="align-center" src="_images/mnist5.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist4.png"><img alt="_images/mnist4.png" class="align-center" src="_images/mnist4.png" style="width: 400px;" /></a>
<p>We now have a fully working deep learning library with most of the
features of a real industrial system like Torch. To take advantage of
this hard work, this module is entirely based on using the
software framework. In particular, we are going to build an image
recognition system. We will do this by build the infrastructure for a
version of LeNet on MNIST: a classic convolutional neural network (CNN)
for digit recognition.</p>
<img alt="_images/networkcnn.png" class="align-center" src="_images/networkcnn.png" />
<p>All starter code is available in <a class="reference external" href="https://github.com/minitorch/Module-4">https://github.com/minitorch/Module-4</a> .</p>
<p>To begin, remember to activate your virtual environment first, and
then clone your assignment:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">git</span> <span class="n">clone</span> <span class="p">{{</span><span class="n">STUDENT_ASSIGNMENT4_URL</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cd</span> <span class="p">{{</span><span class="n">STUDENT_ASSIGNMENT_NAME</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">Ue</span> <span class="o">.</span>
</pre></div>
</div>
<p>You need the files from previous assignments, so maker sure to pull
them over to your new repo.  We recommend you to get familiar with
tensor.py, since you might find some of those functions useful for
implementing this Module.</p>
<p>Additionally, you need to install and download an MNIST library:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pip</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="n">mnist</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mnist_get_data</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>(Mac OS users may need to install wget in order to run the .sh file.)</p>
<p>It will add a <cite>data/</cite> directory in your module.  You can try the
following code to test the installation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mnist</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mndata</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">mndata</span><span class="o">.</span><span class="n">load_training</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
<p>Be sure to continue to follow the <a class="reference internal" href="contributing.html"><span class="doc">Contributing</span></a> guidelines.</p>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convolution.html">Convolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">Pooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="softmax.html">Softmax</a></li>
</ul>
</div>
<div class="section" id="tasks">
<h2>Tasks<a class="headerlink" href="#tasks" title="Permalink to this headline">¶</a></h2>
<div class="section" id="task-4-1-1d-convolution">
<h3>Task 4.1: 1D Convolution<a class="headerlink" href="#task-4-1-1d-convolution" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with convolution.
Be sure to read the Guide on <a class="reference internal" href="convolution.html"><span class="doc">Convolution</span></a>.</p>
</div>
<p>You will implement the 1D convolution in Numba. This function gets used by the
<cite>forward</cite> and <cite>backward</cite> pass of conv1d.</p>
<a class="reference internal image-reference" href="_images/channels.png"><img alt="_images/channels.png" class="align-center" src="_images/channels.png" style="width: 300px;" /></a>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>Complete the following function in <cite>minitorch/fast_conv.py</cite>, and pass tests marked
as <cite>task4_1</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tensor_conv1d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_conv1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">out</span></em>, <em class="sig-param"><span class="n">out_shape</span></em>, <em class="sig-param"><span class="n">out_strides</span></em>, <em class="sig-param"><span class="n">out_size</span></em>, <em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">input_shape</span></em>, <em class="sig-param"><span class="n">input_strides</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">weight_shape</span></em>, <em class="sig-param"><span class="n">weight_strides</span></em>, <em class="sig-param"><span class="n">reverse</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tensor_conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>1D Convolution implementation.</p>
<p>Given input tensor of</p>
<blockquote>
<div><p><cite>batch, in_channels, width</cite></p>
</div></blockquote>
<p>and weight tensor</p>
<blockquote>
<div><p><cite>out_channels, in_channels, k_width</cite></p>
</div></blockquote>
<p>Computes padded output of</p>
<blockquote>
<div><p><cite>batch, out_channels, width</cite></p>
</div></blockquote>
<p><cite>reverse</cite> decides if weight is anchored left (False) or right.
(See diagrams)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of the <cite>out</cite> tensor.</p></li>
<li><p><strong>input</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) -- anchor weight at left or right</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="task-4-2-2d-convolution">
<h3>Task 4.2: 2D Convolution<a class="headerlink" href="#task-4-2-2d-convolution" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with convolution.
Be sure to read the Guide on <a class="reference internal" href="convolution.html"><span class="doc">Convolution</span></a>.</p>
</div>
<p>You will implement the 2D convolution in Numba. This function gets used by the
<cite>forward</cite> and <cite>backward</cite> pass of conv2d.</p>
<a class="reference internal image-reference" href="_images/conv2.png"><img alt="_images/conv2.png" class="align-center" src="_images/conv2.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>Complete the following function in <cite>minitorch/fast_conv.py</cite>, and pass tests marked
as <cite>task4_2</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tensor_conv2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_conv2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">out</span></em>, <em class="sig-param"><span class="n">out_shape</span></em>, <em class="sig-param"><span class="n">out_strides</span></em>, <em class="sig-param"><span class="n">out_size</span></em>, <em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">input_shape</span></em>, <em class="sig-param"><span class="n">input_strides</span></em>, <em class="sig-param"><span class="n">weight</span></em>, <em class="sig-param"><span class="n">weight_shape</span></em>, <em class="sig-param"><span class="n">weight_strides</span></em>, <em class="sig-param"><span class="n">reverse</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tensor_conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>2D Convolution implementation.</p>
<p>Given input tensor of</p>
<blockquote>
<div><p><cite>batch, in_channels, height, width</cite></p>
</div></blockquote>
<p>and weight tensor</p>
<blockquote>
<div><p><cite>out_channels, in_channels, k_height, k_width</cite></p>
</div></blockquote>
<p>Computes padded output of</p>
<blockquote>
<div><p><cite>batch, out_channels, height, width</cite></p>
</div></blockquote>
<p><cite>Reverse</cite> decides if weight is anchored top-left (False) or bottom-right.
(See diagrams)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of the <cite>out</cite> tensor.</p></li>
<li><p><strong>input</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) -- anchor weight at top-left or bottom-right</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="task-4-3-pooling">
<h3>Task 4.3: Pooling<a class="headerlink" href="#task-4-3-pooling" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with pooling.
Be sure to read the Guide on <a class="reference internal" href="pooling.html"><span class="doc">Pooling</span></a>.</p>
</div>
<p>You will implement 2D pooling on tensors with an average operation.</p>
<a class="reference internal image-reference" href="_images/pool2d.png"><img alt="_images/pool2d.png" class="align-center" src="_images/pool2d.png" style="width: 500px;" /></a>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>Complete the following functions in <cite>minitorch/nn.py</cite>, and pass tests
marked as <cite>task4_3</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tile">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tile</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tile" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape an image tensor for 2D pooling</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> (<em>pair of ints</em>) -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of size batch x channel x new_height x new_width x (kernel_height * kernel_width) as well as the new_height and new_width value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>(<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, int, int)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.avgpool2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">avgpool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.avgpool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Tiled average pooling 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> (<em>pair of ints</em>) -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pooled tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="task-4-4-softmax-and-dropout">
<h3>Task 4.4: Softmax and Dropout<a class="headerlink" href="#task-4-4-softmax-and-dropout" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with max reductions.
Be sure to read the Guide on <a class="reference internal" href="softmax.html"><span class="doc">Softmax</span></a>.</p>
</div>
<p>You will implement max, softmax, and log softmax on tensors as well as
the dropout and max-pooling operations.</p>
<a class="reference internal image-reference" href="_images/value.png"><img alt="_images/value.png" class="align-center" src="_images/value.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/softmax.png"><img alt="_images/softmax.png" class="align-center" src="_images/softmax.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<ul class="simple">
<li><p>Complete the following functions in <cite>minitorch/nn.py</cite>, and pass
tests marked as <cite>task4_4</cite>.</p></li>
<li><p>Add a property tests for the function in
<cite>test/test_nn.py</cite> and ensure that you understand its gradient
computation.</p></li>
</ul>
</div>
<dl class="py function">
<dt id="minitorch.max">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">vals</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.max" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="minitorch.softmax">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">dim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the softmax as a tensor.</p>
<div class="math notranslate nohighlight">
\[z_i = \frac{e^{x_i}}{\sum_i e^{x_i}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- input tensor</p></li>
<li><p><strong>dim</strong> (<em>int</em>) -- dimension to apply softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>softmax tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.logsoftmax">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">logsoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">dim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.logsoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log of the softmax as a tensor.</p>
<div class="math notranslate nohighlight">
\[z_i = x_i - \log \sum_i e^{x_i}\]</div>
<p>See <a class="reference external" href="https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations">https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- input tensor</p></li>
<li><p><strong>dim</strong> (<em>int</em>) -- dimension to apply log-softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log of softmax tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.maxpool2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">maxpool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">kernel</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.maxpool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Tiled max pooling 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> (<em>pair of ints</em>) -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pooled tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.dropout">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">dropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span></em>, <em class="sig-param"><span class="n">rate</span></em>, <em class="sig-param"><span class="n">ignore</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Dropout positions based on random noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) -- input tensor</p></li>
<li><p><strong>rate</strong> (<em>float</em>) -- probability [0, 1) of dropping out each position</p></li>
<li><p><strong>ignore</strong> (<em>bool</em>) -- skip dropout, i.e. do nothing at all</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor with random positions dropped out</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="task-4-4b-extra-credit">
<h3>Task 4.4b: Extra Credit<a class="headerlink" href="#task-4-4b-extra-credit" title="Permalink to this headline">¶</a></h3>
<p>Implementing convolution and pooling efficiently is critical for
large-scale image recognition. However, both are a bit harder than
some of the basic CUDA functions we have written so far. For this
task, add an extra file <cite>cuda_conv.py</cite> that implements
<cite>conv2d</cite> or <cite>avgpool2d</cite>  on CUDA.</p>
</div>
<div class="section" id="task-4-5-training-an-image-classifier">
<h3>Task 4.5: Training an Image Classifier<a class="headerlink" href="#task-4-5-training-an-image-classifier" title="Permalink to this headline">¶</a></h3>
<p>If your code works, you should now be able to move on to the MINIST
training script in <cite>project/run_mnist_multiclass.py</cite>.  This script has the
same basic training setup as <a class="reference internal" href="module3.html"><span class="doc">Module 3 - Efficiency</span></a>, but now adapted to image
classification. You need to implement <cite>Conv2D</cite> and <cite>Network</cite>. The Visdom
visualization will show some hidden states of your model, like the following:</p>
<a class="reference internal image-reference" href="_images/mnist5.png"><img alt="_images/mnist5.png" class="align-center" src="_images/mnist5.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist4.png"><img alt="_images/mnist4.png" class="align-center" src="_images/mnist4.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id5">
<p class="admonition-title">Todo</p>
<ul class="simple">
<li><p>Train a model on MNIST, and add your training printout logs (i.e. training loss,
performance on validation set) to the README.</p></li>
<li><p>Report the Visdom visualizations of your final model's
hidden states at the end of training.</p></li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="convolution.html" class="btn btn-neutral float-right" title="Convolution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="cuda.html" class="btn btn-neutral float-left" title="GPU Programming" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Sasha Rush.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>