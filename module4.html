
<!DOCTYPE html>

<html lang="english">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Networks &#8212; MiniTorch 0.3 documentation</title>
    
    <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
    <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Convolution" href="convolution.html" />
    <link rel="prev" title="GPU Programming" href="cuda.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="english">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/minitorch.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="setup.html">
  Setup
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="mlprimer.html">
  ML Primer
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module0.html">
  Fundamentals
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module1.html">
  Autodiff
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module2.html">
  Tensors
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module3.html">
  Efficiency
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="current reference internal nav-link" href="#">
  Networks
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/minitorch/" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/srush_nlp" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p>
 <span class="caption-text">
  Guides
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="convolution.html">
   Convolution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pooling.html">
   Pooling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="softmax.html">
   Softmax
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks">
   Tasks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-1-1d-convolution">
     Task 4.1: 1D Convolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-2-2d-convolution">
     Task 4.2: 2D Convolution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-3-pooling">
     Task 4.3: Pooling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-4-softmax-and-dropout">
     Task 4.4: Softmax and Dropout
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-4b-extra-credit">
     Task 4.4b: Extra Credit
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#task-4-5-training-an-image-classifier">
     Task 4.5: Training an Image Classifier
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="networks">
<h1>Networks<a class="headerlink" href="#networks" title="Permalink to this headline">¶</a></h1>
<a class="reference internal image-reference" href="_images/orig.png"><img alt="_images/orig.png" class="align-center" src="_images/orig.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist2.png"><img alt="_images/mnist2.png" class="align-center" src="_images/mnist2.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist5.png"><img alt="_images/mnist5.png" class="align-center" src="_images/mnist5.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist4.png"><img alt="_images/mnist4.png" class="align-center" src="_images/mnist4.png" style="width: 400px;" /></a>
<p>We now have a fully working deep learning library with most of the
features of a real industrial system like Torch. To take advantage of
this hard work, this module is entirely based on using the
software framework. In particular, we are going to build an image
recognition system. We will do this by build the infrastructure for a
version of LeNet on MNIST: a classic convolutional neural network (CNN)
for digit recognition, and for a 1D conv for NLP sentiment classification.</p>
<img alt="_images/networkcnn.png" class="align-center" src="_images/networkcnn.png" />
<p>All starter code is available in <a class="reference external" href="https://github.com/minitorch/Module-4">https://github.com/minitorch/Module-4</a> .</p>
<p>To begin, remember to activate your virtual environment first, and
then clone your assignment:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">git</span> <span class="n">clone</span> <span class="p">{{</span><span class="n">STUDENT_ASSIGNMENT4_URL</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cd</span> <span class="p">{{</span><span class="n">STUDENT_ASSIGNMENT_NAME</span><span class="p">}}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">Ue</span> <span class="o">.</span>
</pre></div>
</div>
<p>You need the files from previous assignments, so maker sure to pull
them over to your new repo.  We recommend you to get familiar with
tensor.py, since you might find some of those functions useful for
implementing this Module.</p>
<p>Additionally, you need to install and download an MNIST library:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pip</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="n">mnist</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cd</span> <span class="n">project</span><span class="o">/</span> <span class="p">;</span> <span class="n">mnist_get_data</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>(Mac OS users may need to install wget in order to run the .sh file.)</p>
<p>It will add a <cite>data/</cite> directory in your module.  You can try the
following code to test the installation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mnist</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mndata</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">mndata</span><span class="o">.</span><span class="n">load_training</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
</pre></div>
</div>
<p>Be sure to continue to follow the <a class="reference internal" href="contributing.html"><span class="doc">Contributing</span></a> guidelines.</p>
<div class="toctree-wrapper compound">
<p><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="convolution.html">Convolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="pooling.html">Pooling</a></li>
<li class="toctree-l1"><a class="reference internal" href="softmax.html">Softmax</a></li>
</ul>
</div>
<section id="tasks">
<h2>Tasks<a class="headerlink" href="#tasks" title="Permalink to this headline">¶</a></h2>
<section id="task-4-1-1d-convolution">
<h3>Task 4.1: 1D Convolution<a class="headerlink" href="#task-4-1-1d-convolution" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with convolution.
Be sure to read the Guide on <a class="reference internal" href="convolution.html"><span class="doc">Convolution</span></a>.</p>
</div>
<p>You will implement the 1D convolution in Numba. This function gets used by the
<cite>forward</cite> and <cite>backward</cite> pass of conv1d.</p>
<a class="reference internal image-reference" href="_images/convchan.png"><img alt="_images/convchan.png" class="align-center" src="_images/convchan.png" style="width: 300px;" /></a>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>Complete the following function in <cite>minitorch/fast_conv.py</cite>, and pass tests marked
as <cite>task4_1</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tensor_conv1d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_conv1d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">out</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">out_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">out_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">out_size</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">input_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">input_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">weight_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">weight_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">reverse</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#minitorch.tensor_conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>1D Convolution implementation.</p>
<p>Given input tensor of</p>
<blockquote>
<div><p><cite>batch, in_channels, width</cite></p>
</div></blockquote>
<p>and weight tensor</p>
<blockquote>
<div><p><cite>out_channels, in_channels, k_width</cite></p>
</div></blockquote>
<p>Computes padded output of</p>
<blockquote>
<div><p><cite>batch, out_channels, width</cite></p>
</div></blockquote>
<p><cite>reverse</cite> decides if weight is anchored left (False) or right.
(See diagrams)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of the <cite>out</cite> tensor.</p></li>
<li><p><strong>input</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) -- anchor weight at left or right</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="task-4-2-2d-convolution">
<h3>Task 4.2: 2D Convolution<a class="headerlink" href="#task-4-2-2d-convolution" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with convolution.
Be sure to read the Guide on <a class="reference internal" href="convolution.html"><span class="doc">Convolution</span></a>.</p>
</div>
<p>You will implement the 2D convolution in Numba. This function gets used by the
<cite>forward</cite> and <cite>backward</cite> pass of conv2d.</p>
<a class="reference internal image-reference" href="_images/conv2.png"><img alt="_images/conv2.png" class="align-center" src="_images/conv2.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>Complete the following function in <cite>minitorch/fast_conv.py</cite>, and pass tests marked
as <cite>task4_2</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tensor_conv2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_conv2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">out</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">out_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">out_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">out_size</span><span class="p">:</span> <span class="n">int</span></em>, <em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">input_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">input_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">weight</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">weight_shape</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">weight_strides</span><span class="p">:</span> <span class="n">numpy.ndarray<span class="p">[</span>Any<span class="p">, </span>numpy.dtype<span class="p">[</span>numpy.int32<span class="p">]</span><span class="p">]</span></span></em>, <em class="sig-param"><span class="n">reverse</span><span class="p">:</span> <span class="n">bool</span></em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#minitorch.tensor_conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>2D Convolution implementation.</p>
<p>Given input tensor of</p>
<blockquote>
<div><p><cite>batch, in_channels, height, width</cite></p>
</div></blockquote>
<p>and weight tensor</p>
<blockquote>
<div><p><cite>out_channels, in_channels, k_height, k_width</cite></p>
</div></blockquote>
<p>Computes padded output of</p>
<blockquote>
<div><p><cite>batch, out_channels, height, width</cite></p>
</div></blockquote>
<p><cite>Reverse</cite> decides if weight is anchored top-left (False) or bottom-right.
(See diagrams)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of the <cite>out</cite> tensor.</p></li>
<li><p><strong>input</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>input_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight</strong> (<em>array</em>) -- storage for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_shape</strong> (<em>array</em>) -- shape for <cite>input</cite> tensor.</p></li>
<li><p><strong>weight_strides</strong> (<em>array</em>) -- strides for <cite>input</cite> tensor.</p></li>
<li><p><strong>reverse</strong> (<em>bool</em>) -- anchor weight at top-left or bottom-right</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="task-4-3-pooling">
<h3>Task 4.3: Pooling<a class="headerlink" href="#task-4-3-pooling" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with pooling.
Be sure to read the Guide on <a class="reference internal" href="pooling.html"><span class="doc">Pooling</span></a>.</p>
</div>
<p>You will implement 2D pooling on tensors with an average operation.</p>
<a class="reference internal image-reference" href="_images/pool2d.png"><img alt="_images/pool2d.png" class="align-center" src="_images/pool2d.png" style="width: 500px;" /></a>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>Complete the following functions in <cite>minitorch/nn.py</cite>, and pass tests
marked as <cite>task4_3</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tile">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tile</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">kernel</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>minitorch.tensor.Tensor<span class="p">, </span>int<span class="p">, </span>int<span class="p">]</span><a class="headerlink" href="#minitorch.tile" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshape an image tensor for 2D pooling</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of size batch x channel x new_height x new_width x (kernel_height * kernel_width) as well as the new_height and new_width value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.avgpool2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">avgpool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">kernel</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; minitorch.tensor.Tensor<a class="headerlink" href="#minitorch.avgpool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Tiled average pooling 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Pooled tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="task-4-4-softmax-and-dropout">
<h3>Task 4.4: Softmax and Dropout<a class="headerlink" href="#task-4-4-softmax-and-dropout" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires basic familiarity with max reductions.
Be sure to read the Guide on <a class="reference internal" href="softmax.html"><span class="doc">Softmax</span></a>.</p>
</div>
<p>You will implement max, softmax, and log softmax on tensors as well as
the dropout and max-pooling operations.</p>
<a class="reference internal image-reference" href="_images/value.png"><img alt="_images/value.png" class="align-center" src="_images/value.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/softmax.png"><img alt="_images/softmax.png" class="align-center" src="_images/softmax.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<ul class="simple">
<li><p>Complete the following functions in <cite>minitorch/nn.py</cite>, and pass
tests marked as <cite>task4_4</cite>.</p></li>
<li><p>Add a property tests for the function in
<cite>test/test_nn.py</cite> and ensure that you understand its gradient
computation.</p></li>
</ul>
</div>
<dl class="py function">
<dt id="minitorch.max">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">max</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">vals</span><span class="p">:</span> <span class="n">Tensor</span></em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#minitorch.max" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt id="minitorch.softmax">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">softmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">dim</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; minitorch.tensor.Tensor<a class="headerlink" href="#minitorch.softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the softmax as a tensor.</p>
<div class="math notranslate nohighlight">
\[z_i = \frac{e^{x_i}}{\sum_i e^{x_i}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- input tensor</p></li>
<li><p><strong>dim</strong> -- dimension to apply softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>softmax tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.logsoftmax">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">logsoftmax</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">dim</span><span class="p">:</span> <span class="n">int</span></em><span class="sig-paren">)</span> &#x2192; minitorch.tensor.Tensor<a class="headerlink" href="#minitorch.logsoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the log of the softmax as a tensor.</p>
<div class="math notranslate nohighlight">
\[z_i = x_i - \log \sum_i e^{x_i}\]</div>
<p>See <a class="reference external" href="https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations">https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- input tensor</p></li>
<li><p><strong>dim</strong> -- dimension to apply log-softmax</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log of softmax tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.maxpool2d">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">maxpool2d</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">kernel</span><span class="p">:</span> <span class="n">Tuple<span class="p">[</span>int<span class="p">, </span>int<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; minitorch.tensor.Tensor<a class="headerlink" href="#minitorch.maxpool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Tiled max pooling 2D</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- batch x channel x height x width</p></li>
<li><p><strong>kernel</strong> -- height x width of pooling</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>pooled tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.dropout">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">dropout</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input</span><span class="p">:</span> <span class="n">minitorch.tensor.Tensor</span></em>, <em class="sig-param"><span class="n">rate</span><span class="p">:</span> <span class="n">float</span></em>, <em class="sig-param"><span class="n">ignore</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; minitorch.tensor.Tensor<a class="headerlink" href="#minitorch.dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Dropout positions based on random noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> -- input tensor</p></li>
<li><p><strong>rate</strong> -- probability [0, 1) of dropping out each position</p></li>
<li><p><strong>ignore</strong> -- skip dropout, i.e. do nothing at all</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tensor with randoom positions dropped out</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="task-4-4b-extra-credit">
<h3>Task 4.4b: Extra Credit<a class="headerlink" href="#task-4-4b-extra-credit" title="Permalink to this headline">¶</a></h3>
<p>Implementing convolution and pooling efficiently is critical for
large-scale image recognition. However, both are a bit harder than
some of the basic CUDA functions we have written so far. For this
task, add an extra file <cite>cuda_conv.py</cite> that implements
<cite>conv1d</cite> and <cite>conv2d</cite>  on CUDA. Show the output on colab.</p>
</section>
<section id="task-4-5-training-an-image-classifier">
<h3>Task 4.5: Training an Image Classifier<a class="headerlink" href="#task-4-5-training-an-image-classifier" title="Permalink to this headline">¶</a></h3>
<p>If your code works, you should now be able to move on to the NLP and
CV training scripts in <cite>project/run_sentiment.py</cite> and
<cite>project/run_mnist_multiclass.py</cite>.  This script has the same basic
training setup as <a class="reference internal" href="module3.html"><span class="doc">Efficiency</span></a>, but now adapted to sentiment and
image classification. You need to implement <cite>Conv1D</cite>, <cite>Conv2D</cite>, and
<cite>Network</cite> for both files.</p>
<p>We recommend running on the command line when testing.
But you can also use the Streamlit visualization to view
hidden states of your model, like the following:</p>
<a class="reference internal image-reference" href="_images/mnist5.png"><img alt="_images/mnist5.png" class="align-center" src="_images/mnist5.png" style="width: 400px;" /></a>
<a class="reference internal image-reference" href="_images/mnist4.png"><img alt="_images/mnist4.png" class="align-center" src="_images/mnist4.png" style="width: 400px;" /></a>
<div class="admonition-todo admonition" id="id5">
<p class="admonition-title">Todo</p>
<ul class="simple">
<li><p>Train a model on Sentiment (SST2), and add your training printout
logs (i.e. training loss, performance on validation set) to the
README. (The model should get to 75% best validation accuracy.)</p></li>
<li><p>Train a model on Digit classification (MNIST), and add your
training printout logs (i.e. training loss, performance on
validation set) to the README.</p></li>
<li><p>Report the Streamlit visualizations of your final model's hidden
states at the end of training.</p></li>
</ul>
</div>
</section>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="cuda.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">GPU Programming</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="convolution.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Convolution</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Sasha Rush.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>